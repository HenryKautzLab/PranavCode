Here I have added two starter codes. The Flickr one with other extraneous files outside is my first version for experimentation / getting used to things.
- Used BLIP generated captions for images, found them to be too generic
- Could revisit and find ways to create better captions, seems like more traditional/specialized way

In the TikTokSS folder is the most recent one where I used an exisiting model to analyze an image and retreieve relevant data by adding specifications to a prompt.
- Generated captions for this image was much more specific, useful, and accurate. Used gemini model to analyze image and output the caption with a specified prompt
- Will look into other models and try on multiple images of different context

This repo will continue to be updated as I try to advance and add layers of complexity.

Link to Technical Document:
https://docs.google.com/document/d/15UdZD-YeCTmvvoogqotaDxWpPrW_yz2_DM5TWk2ND6A/edit?tab=t.0
